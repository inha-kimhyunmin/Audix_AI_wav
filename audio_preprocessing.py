from config import SAMPLE_RATE
from model import load_model, separate
from mel import save_mel_tensor
from rms_normalize import adaptive_level_adjust, calculate_rms, rms_to_db
from datetime import datetime
from resample import init_resampler
import time
import json
import torchaudio
import torch

def load_wav_file(wav_path):
    """
    WAV íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    
    :param wav_path: WAV íŒŒì¼ ê²½ë¡œ
    :return: ì˜¤ë””ì˜¤ í…ì„œ (shape: [channels, samples])
    """
    waveform, sample_rate = torchaudio.load(wav_path)
    
    # ìƒ˜í”Œë§ ë ˆì´íŠ¸ í™•ì¸
    if sample_rate != SAMPLE_RATE:
        print(f"âš ï¸ ìƒ˜í”Œë§ ë ˆì´íŠ¸ ë¶ˆì¼ì¹˜: {sample_rate}Hz -> {SAMPLE_RATE}Hzë¡œ ë¦¬ìƒ˜í”Œë§")
        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=SAMPLE_RATE)
        waveform = resampler(waveform)
    
    # ëª¨ë…¸ ì±„ë„ë¡œ ë³€í™˜ (ìš”ì²­ì‚¬í•­ì— ë”°ë¼)
    if waveform.shape[0] > 1:
        waveform = torch.mean(waveform, dim=0, keepdim=True)
    
    # 10ì´ˆ ê¸¸ì´ë¡œ ë§ì¶”ê¸° (íŒ¨ë”© ë˜ëŠ” ìë¥´ê¸°)
    target_length = SAMPLE_RATE * 10  # 10ì´ˆ
    current_length = waveform.shape[1]
    
    if current_length < target_length:
        # íŒ¨ë”©
        padding = target_length - current_length
        waveform = torch.nn.functional.pad(waveform, (0, padding))
    elif current_length > target_length:
        # ìë¥´ê¸°
        waveform = waveform[:, :target_length]
    
    print(f"ğŸ“ WAV íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {wav_path}")
    print(f"ğŸ”Š ì˜¤ë””ì˜¤ í˜•íƒœ: {waveform.shape} (ìƒ˜í”Œë§ ë ˆì´íŠ¸: {SAMPLE_RATE}Hz)")
    
    return waveform

def process_wav_file(model, source_names, wav_path, target_parts=None):
    """
    WAV íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  .pt íŒŒì¼ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    :param model: ë¶„ë¦¬ ëª¨ë¸
    :param source_names: ë¶€í’ˆ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['fan', 'pump', ...])
    :param wav_path: ì…ë ¥ WAV íŒŒì¼ ê²½ë¡œ
    :param target_parts: ë¶„ì„í•  ë¶€í’ˆ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['fan', 'pump']) - Noneì´ë©´ ëª¨ë“  ë¶€í’ˆ ì²˜ë¦¬
    :return: ìƒì„±ëœ .pt íŒŒì¼ ê²½ë¡œë“¤
    """
    print(f"\nğŸµ WAV íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {wav_path}")
    
    # íƒ€ê²Ÿ ë¶€í’ˆì´ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ noiseë¥¼ ì œì™¸í•œ ëª¨ë“  ë¶€í’ˆ ì²˜ë¦¬
    if target_parts is None:
        target_parts = [src for src in source_names if src.lower() != "noise"]
    
    print(f"ğŸ¯ ë¶„ì„ ëŒ€ìƒ ë¶€í’ˆ: {target_parts}")
    
    # ìœ íš¨í•œ ë¶€í’ˆì¸ì§€ í™•ì¸
    available_parts = [src for src in source_names if src.lower() != "noise"]
    invalid_parts = [part for part in target_parts if part not in available_parts]
    if invalid_parts:
        raise ValueError(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¶€í’ˆ: {invalid_parts}. ì‚¬ìš© ê°€ëŠ¥í•œ ë¶€í’ˆ: {available_parts}")
    
    # WAV íŒŒì¼ ë¡œë“œ
    start_load = time.time()
    audio = load_wav_file(wav_path)
    end_load = time.time()
    print(f"ğŸ“‚ íŒŒì¼ ë¡œë“œ ì‹œê°„: {(end_load - start_load):.2f}ì´ˆ")
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
    timestamp_str = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    
    # ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
    generated_files = []
    
    # 1. ì ì‘ì  ë ˆë²¨ ì¡°ì • (ì‘ì€ ì†Œë¦¬ëŠ” ì¦í­, í° ì†Œë¦¬ëŠ” ì••ì¶•)
    start_normalize = time.time()
    current_rms = calculate_rms(audio.squeeze())  # ëª¨ë…¸ ì±„ë„ì´ë¯€ë¡œ squeeze ì‚¬ìš©
    current_db = rms_to_db(current_rms)
    print(f"ğŸ“Š ì›ë³¸ ì˜¤ë””ì˜¤ RMS: {current_db:.2f}dB")
    
    normalized_audio = adaptive_level_adjust(audio.squeeze())
    
    # adaptive_level_adjustê°€ tensorë¥¼ ë°˜í™˜í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ numpyë¡œ ë³€í™˜
    if isinstance(normalized_audio, torch.Tensor):
        normalized_audio = normalized_audio.numpy()
    
    end_normalize = time.time()
    print(f"ğŸ”§ ì ì‘ì  ë ˆë²¨ ì¡°ì • ì‹œê°„: {(end_normalize - start_normalize):.2f}ì´ˆ")
    
    # 2. ë¶„ë¦¬
    start_sep = time.time()
    sources = separate(model, normalized_audio)
    end_sep = time.time()
    print(f"ğŸ›ï¸ ì†Œë¦¬ ë¶„ë¦¬ ì‹œê°„: {(end_sep - start_sep):.2f}ì´ˆ")
    
    # 3. ì €ì¥ (target_partsì— ìˆëŠ” ë¶€í’ˆë§Œ ì €ì¥)
    start_save = time.time()
    saved_count = 0
    
    for src_idx, src in enumerate(sources):
        if src_idx < len(source_names):
            src_name = source_names[src_idx]
            
            # target_partsì— ì—†ëŠ” ë¶€í’ˆì€ ê±´ë„ˆë›°ê¸°
            if src_name not in target_parts:
                print(f"â­ï¸ {src_name} ê±´ë„ˆë›°ê¸° (ë¶„ì„ ëŒ€ìƒ ì•„ë‹˜)")
                continue
            
            # noiseëŠ” ì´ë¯¸ target_partsì—ì„œ ì œì™¸ë¨
            file_path = save_mel_tensor(src, 1, src_name, timestamp_str, target_parts)  # ë§ˆì´í¬ ë²ˆí˜¸ë¥¼ 1ë¡œ ê³ ì •
            
            if file_path:  # ì €ì¥ì´ ì„±ê³µí•œ ê²½ìš°
                generated_files.append(file_path)
                saved_count += 1
                print(f"ğŸ“ ì €ì¥ ì™„ë£Œ: {src_name}")
    
    # ë¶„ë¦¬ëœ ì†ŒìŠ¤ ìˆ˜ ì •ë³´ ì¶œë ¥
    total_sources = len(sources)
    print(f"ğŸ›ï¸ ì´ {total_sources}ê°œ ì†ŒìŠ¤ ë¶„ë¦¬ ì™„ë£Œ (ì €ì¥: {saved_count}ê°œ, ê±´ë„ˆë›°ê¸°: {total_sources - saved_count}ê°œ)")
    
    end_save = time.time()
    print(f"ğŸ’¾ ì €ì¥ ì‹œê°„: {(end_save - start_save):.2f}ì´ˆ")
    
    # ìƒì„±ëœ .pt íŒŒì¼ ê²½ë¡œë“¤ ë°˜í™˜
    return generated_files

def process_multiple_wav_files(model, source_names, wav_paths, target_parts=None):
    """
    ì—¬ëŸ¬ WAV íŒŒì¼ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•´ì„œ .pt íŒŒì¼ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    :param model: ë¶„ë¦¬ ëª¨ë¸
    :param source_names: ë¶€í’ˆ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
    :param wav_paths: WAV íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    :param target_parts: ë¶„ì„í•  ë¶€í’ˆ ë¦¬ìŠ¤íŠ¸
    :return: ëª¨ë“  ìƒì„±ëœ .pt íŒŒì¼ ê²½ë¡œë“¤
    """
    all_generated_files = []
    
    for i, wav_path in enumerate(wav_paths):
        print(f"\nğŸ”„ íŒŒì¼ {i+1}/{len(wav_paths)} ì²˜ë¦¬ ì¤‘: {wav_path}")
        try:
            generated_files = process_wav_file(model, source_names, wav_path, target_parts=target_parts)
            all_generated_files.extend(generated_files)
        except Exception as e:
            print(f"âŒ íŒŒì¼ {wav_path} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    return all_generated_files


if __name__ == "__main__":
    model, source_names = load_model()
    init_resampler(model.samplerate)
    
    # ì˜ˆì‹œ: WAV íŒŒì¼ ì²˜ë¦¬
    wav_file_path = "test01/mixture.wav"  # ì²˜ë¦¬í•  WAV íŒŒì¼ ê²½ë¡œ
    target_parts = ["fan", "pump"]  # ì´ WAV íŒŒì¼ì— í¬í•¨ëœ ë¶€í’ˆë“¤ (ì‹¤ì œ ìƒí™©ì— ë§ê²Œ ìˆ˜ì •)
    
    try:
        generated_files = process_wav_file(model, source_names, wav_file_path, target_parts=target_parts)
        
        # ê²°ê³¼ ì¶œë ¥
        print("\nğŸ“Š ìƒì„±ëœ .pt íŒŒì¼ë“¤:")
        for file_path in generated_files:
            print(f"  âœ… {file_path}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
