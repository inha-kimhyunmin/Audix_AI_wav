from config import CHANNEL_PARTS, SAMPLE_RATE
from model import load_model, separate
from mel import save_mel_tensor
from rms_normalize import adaptive_level_adjust, calculate_rms, rms_to_db
from datetime import datetime
from resample import init_resampler
import time
import json
import torchaudio
import torch

def load_wav_file(wav_path):
    """
    WAV íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    
    :param wav_path: WAV íŒŒì¼ ê²½ë¡œ
    :return: ì˜¤ë””ì˜¤ í…ì„œ (shape: [channels, samples])
    """
    waveform, sample_rate = torchaudio.load(wav_path)
    
    # ìƒ˜í”Œë§ ë ˆì´íŠ¸ í™•ì¸
    if sample_rate != SAMPLE_RATE:
        print(f"âš ï¸ ìƒ˜í”Œë§ ë ˆì´íŠ¸ ë¶ˆì¼ì¹˜: {sample_rate}Hz -> {SAMPLE_RATE}Hzë¡œ ë¦¬ìƒ˜í”Œë§")
        resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=SAMPLE_RATE)
        waveform = resampler(waveform)
    
    # ëª¨ë…¸ ì±„ë„ë¡œ ë³€í™˜ (ìš”ì²­ì‚¬í•­ì— ë”°ë¼)
    if waveform.shape[0] > 1:
        waveform = torch.mean(waveform, dim=0, keepdim=True)
    
    # 10ì´ˆ ê¸¸ì´ë¡œ ë§ì¶”ê¸° (íŒ¨ë”© ë˜ëŠ” ìë¥´ê¸°)
    target_length = SAMPLE_RATE * 10  # 10ì´ˆ
    current_length = waveform.shape[1]
    
    if current_length < target_length:
        # íŒ¨ë”©
        padding = target_length - current_length
        waveform = torch.nn.functional.pad(waveform, (0, padding))
    elif current_length > target_length:
        # ìë¥´ê¸°
        waveform = waveform[:, :target_length]
    
    print(f"ğŸ“ WAV íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {wav_path}")
    print(f"ğŸ”Š ì˜¤ë””ì˜¤ í˜•íƒœ: {waveform.shape} (ìƒ˜í”Œë§ ë ˆì´íŠ¸: {SAMPLE_RATE}Hz)")
    
    return waveform

def process_wav_file(model, source_names, wav_path):
    """
    WAV íŒŒì¼ì„ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    :param model: ë¶„ë¦¬ ëª¨ë¸
    :param source_names: ë¶€í’ˆ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['fan', 'pump', ...])
    :param wav_path: ì…ë ¥ WAV íŒŒì¼ ê²½ë¡œ
    :return: ì²˜ë¦¬ ê²°ê³¼ JSON
    """
    print(f"\nğŸµ WAV íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {wav_path}")
    
    # WAV íŒŒì¼ ë¡œë“œ
    start_load = time.time()
    audio = load_wav_file(wav_path)
    end_load = time.time()
    print(f"ğŸ“‚ íŒŒì¼ ë¡œë“œ ì‹œê°„: {(end_load - start_load):.2f}ì´ˆ")
    
    # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
    timestamp_str = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    
    # ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
    results = []
    
    # ìŠ¤í…Œë ˆì˜¤ë¡œ ë³€í™˜ (2ì±„ë„ë¡œ ë³µì‚¬)
    if audio.shape[0] == 1:
        audio = audio.repeat(2, 1)  # [2, samples]
    
    # ê° ë§ˆì´í¬(ì±„ë„)ë³„ ì²˜ë¦¬
    for mic_idx in range(audio.shape[0]):
        print(f"\nğŸ§ ë§ˆì´í¬ {mic_idx + 1} ì²˜ë¦¬ ì¤‘")
        start_total = time.time()
        
        # 1. ì ì‘ì  ë ˆë²¨ ì¡°ì • (ì‘ì€ ì†Œë¦¬ëŠ” ì¦í­, í° ì†Œë¦¬ëŠ” ì••ì¶•)
        start_normalize = time.time()
        current_rms = calculate_rms(audio[mic_idx])
        current_db = rms_to_db(current_rms)
        print(f"ğŸ“Š ì›ë³¸ ì˜¤ë””ì˜¤ RMS: {current_db:.2f}dB")
        
        normalized_audio = adaptive_level_adjust(audio[mic_idx])
        
        # adaptive_level_adjustê°€ tensorë¥¼ ë°˜í™˜í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ numpyë¡œ ë³€í™˜
        if isinstance(normalized_audio, torch.Tensor):
            normalized_audio = normalized_audio.numpy()
        
        end_normalize = time.time()
        print(f"ğŸ”§ ì ì‘ì  ë ˆë²¨ ì¡°ì • ì‹œê°„: {(end_normalize - start_normalize):.2f}ì´ˆ")
        
        # 2. ë¶„ë¦¬
        start_sep = time.time()
        sources = separate(model, normalized_audio)
        end_sep = time.time()
        print(f"ğŸ›ï¸ ì†Œë¦¬ ë¶„ë¦¬ ì‹œê°„: {(end_sep - start_sep):.2f}ì´ˆ")
        
        # 3. ì €ì¥ (noiseëŠ” ì œì™¸)
        start_save = time.time()
        parts_for_mic = CHANNEL_PARTS[mic_idx]
        for src_idx, src in enumerate(sources):
            if src_idx < len(source_names):
                src_name = source_names[src_idx]
                
                # noiseëŠ” ì €ì¥í•˜ì§€ ì•ŠìŒ
                if src_name.lower() == "noise":
                    print(f"ğŸ—‘ï¸ Noise ì†ŒìŠ¤ ë¬´ì‹œ: {src_name}")
                    continue
                
                file_path = save_mel_tensor(src, mic_idx + 1, src_name, timestamp_str, parts_for_mic)
                
                if file_path:  # ì €ì¥ì´ ì„±ê³µí•œ ê²½ìš°
                    result_entry = {
                        "mic_number": mic_idx + 1,
                        "part_name": src_name,
                        "file_path": file_path
                    }
                    results.append(result_entry)
                    print(f"ğŸ“ ì €ì¥ ì™„ë£Œ: {src_name}")
        
        # ë¶„ë¦¬ëœ ì†ŒìŠ¤ ìˆ˜ ì •ë³´ ì¶œë ¥
        total_sources = len(sources)
        saved_sources = len([s for s in source_names[:total_sources] if s.lower() != "noise"])
        print(f"ğŸ›ï¸ ì´ {total_sources}ê°œ ì†ŒìŠ¤ ë¶„ë¦¬ ì™„ë£Œ (ì €ì¥: {saved_sources}ê°œ, ë¬´ì‹œ: {total_sources - saved_sources}ê°œ)")
        
        end_save = time.time()
        print(f"ğŸ’¾ ì €ì¥ ì‹œê°„: {(end_save - start_save):.2f}ì´ˆ")
        
        # ì´ ì‹œê°„
        end_total = time.time()
        print(f"â±ï¸ ë§ˆì´í¬ {mic_idx + 1} ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {(end_total - start_total):.2f}ì´ˆ")
    
    # JSON ê²°ê³¼ ë°˜í™˜
    result_json = {
        "input_file": wav_path,
        "timestamp": timestamp_str,
        "processed_files": results
    }
    
    return result_json

def process_multiple_wav_files(model, source_names, wav_paths):
    """
    ì—¬ëŸ¬ WAV íŒŒì¼ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    
    :param model: ë¶„ë¦¬ ëª¨ë¸
    :param source_names: ë¶€í’ˆ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
    :param wav_paths: WAV íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
    :return: ëª¨ë“  ì²˜ë¦¬ ê²°ê³¼ë¥¼ í¬í•¨í•œ JSON
    """
    all_results = []
    
    for i, wav_path in enumerate(wav_paths):
        print(f"\nğŸ”„ íŒŒì¼ {i+1}/{len(wav_paths)} ì²˜ë¦¬ ì¤‘: {wav_path}")
        try:
            result = process_wav_file(model, source_names, wav_path)
            all_results.append(result)
        except Exception as e:
            print(f"âŒ íŒŒì¼ {wav_path} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            error_result = {
                "input_file": wav_path,
                "error": str(e),
                "processed_files": []
            }
            all_results.append(error_result)
    
    final_result = {
        "batch_processing": True,
        "total_files": len(wav_paths),
        "successful_files": len([r for r in all_results if "error" not in r]),
        "results": all_results
    }
    
    return final_result
    """
    ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ ì²˜ë¦¬í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
    
    :param model: ë¶„ë¦¬ ëª¨ë¸
    :param source_names: ë¶€í’ˆ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['fan', 'pump', ...])
    :param repeat: ë°˜ë³µ íšŸìˆ˜
    """
    noise_clip = load_noise_clip()

    for i in range(repeat):
        print(f"\nğŸ“¡ ë°˜ë³µ {i+1}/{repeat}")

        start_record = time.time()
        audio = record_segment()
        end_record = time.time()
        print(f"ğŸ™ï¸ ë…¹ìŒ ì™„ë£Œ: {(end_record - start_record):.2f}ì´ˆ")
        print("audio.shape = ", audio.shape)
        print(f"audio = {audio}, type : {type(audio)}")

        timestamp_str = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")

        for mic_idx in range(audio.shape[1]):
            print(f"\nğŸ§ ë§ˆì´í¬ {mic_idx + 1} ì²˜ë¦¬ ì¤‘")
            start_total = time.time()

            # 1. ì¡ìŒ ì œê±°
            start_denoise = time.time()
            clean = denoise(audio[:, mic_idx], noise_clip)
            end_denoise = time.time()
            print(f"clean : {clean}, type : {type(clean)}")
            print(f"ğŸ§¹ ì¡ìŒ ì œê±° ì‹œê°„: {(end_denoise - start_denoise):.2f}ì´ˆ")

            # 2. ë¶„ë¦¬
            start_sep = time.time()
            sources = separate(model, clean)
            end_sep = time.time()
            print(f"sources = {sources}, type : {type(sources)}")
            print(f"ğŸ›ï¸ ì†Œë¦¬ ë¶„ë¦¬ ì‹œê°„: {(end_sep - start_sep):.2f}ì´ˆ")

            # 3. ì €ì¥
            start_save = time.time()
            parts_for_mic = CHANNEL_PARTS[mic_idx]
            for src_idx, src in enumerate(sources):
                src_name = source_names[src_idx]
                mel_result = save_mel_tensor(src, mic_idx + 1, src_name, timestamp_str, parts_for_mic)
                print(f"ğŸ“ ì €ì¥ ì™„ë£Œ: {src_name}")
            end_save = time.time()
            print(f"ğŸ’¾ ì €ì¥ ì‹œê°„: {(end_save - start_save):.2f}ì´ˆ")

            # ì´ ì‹œê°„
            end_total = time.time()
            print(f"â±ï¸ ë§ˆì´í¬ {mic_idx + 1} ì „ì²´ ì²˜ë¦¬ ì‹œê°„: {(end_total - start_total):.2f}ì´ˆ")

if __name__ == "__main__":
    model, source_names = load_model()
    init_resampler(model.samplerate)
    
    # ì˜ˆì‹œ: WAV íŒŒì¼ ì²˜ë¦¬
    wav_file_path = "test01/mix.wav"  # ì²˜ë¦¬í•  WAV íŒŒì¼ ê²½ë¡œ
    
    try:
        result = process_wav_file(model, source_names, wav_file_path)
        
        # ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì¶œë ¥
        print("\nğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
        print(json.dumps(result, indent=2, ensure_ascii=False))
        
        # ì„ íƒì ìœ¼ë¡œ JSON íŒŒì¼ë¡œ ì €ì¥
        json_filename = f"result_{result['timestamp']}.json"
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ ê²°ê³¼ JSON íŒŒì¼ ì €ì¥: {json_filename}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
